# Llama Inference JAX

This repository runs the Llama-3.2-1B-Instruct model using JAX.

## How to start

1. Download the model files from:
   https://huggingface.co/benjamin/Llama-3.2-1B-Instruct-flax

2. Create the following directory:
   models/llama3_2_1b_instruct_flax/

3. Place the following files into that directory:
   - config.json
   - flax_model.msgpack
   - tokenizer.json
   - tokenizer_config.json
   - special_tokens_map.json